{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regime Transition Trading: 1-Day Directional Strategy\n",
    "\n",
    "**Objective:** Filter HMM regime transitions to identify profitable 1-day directional trades.\n",
    "\n",
    "**Core Hypothesis:** Not all regime transitions are created equal. Some transitions create exploitable 1-day directional moves after transaction costs.\n",
    "\n",
    "**Fixed Parameters:**\n",
    "- Trading horizon: Exactly 1 day (t → t+1)\n",
    "- Transaction costs: 5 bps round-trip\n",
    "- Directional trade only (long or short spread)\n",
    "\n",
    "**Pipeline:**\n",
    "1. Identify all regime transitions\n",
    "2. Label each transition: profitable (1) or unprofitable (0) after costs\n",
    "3. Engineer transition-specific features\n",
    "4. Train ML classifier to filter profitable transitions\n",
    "5. Add KNN similarity matching\n",
    "6. Combine scores into trading filter\n",
    "7. Backtest: trade only high-score transitions\n",
    "\n",
    "**Success Criterion:** Sharpe > 0 after costs (baseline: trade all transitions)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from scipy.stats import entropy\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from hmmlearn import hmm\n",
    "\n",
    "Path('../results/transition_trading').mkdir(parents=True, exist_ok=True)\n",
    "Path('../results/figures').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and HMM Regime Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/processed/full_processed_data_hmm.csv', index_col=0, parse_dates=True)\n",
    "lqd = pd.read_csv('../data/processed/lqd_etf_data.csv', index_col=0, parse_dates=True)\n",
    "df = df.join(lqd, how='inner')\n",
    "\n",
    "# Microstructure features for HMM\n",
    "df['spread_change'] = df['spread'].diff()\n",
    "df['spread_change_abs'] = df['spread_change'].abs()\n",
    "df['spread_accel'] = df['spread_change'].diff()\n",
    "df['spread_rvol_10d'] = df['spread_change'].rolling(window=10).std()\n",
    "df['lqd_log_volume'] = np.log(df['lqd_volume'] + 1)\n",
    "\n",
    "df = df.dropna()\n",
    "df = df.loc['2015-01-01':'2024-12-31'].copy()\n",
    "\n",
    "print(f\"Sample period: {df.index.min().date()} to {df.index.max().date()}\")\n",
    "print(f\"Total observations: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit HMM\n",
    "feature_cols_hmm = ['vix', 'spread_change_abs', 'spread_rvol_10d', 'spread_accel', 'lqd_log_volume']\n",
    "scaler_hmm = StandardScaler()\n",
    "features_std = scaler_hmm.fit_transform(df[feature_cols_hmm].values)\n",
    "\n",
    "model = hmm.GaussianHMM(n_components=3, covariance_type='diag', n_iter=1000, random_state=42)\n",
    "model.fit(features_std)\n",
    "state_sequence = model.predict(features_std)\n",
    "\n",
    "# Get state probabilities\n",
    "state_probs = model.predict_proba(features_std)\n",
    "\n",
    "# Relabel states\n",
    "df['state_raw'] = state_sequence\n",
    "state_vix = df.groupby('state_raw')['vix'].mean()\n",
    "state_vol = df.groupby('state_raw')['spread_rvol_10d'].mean()\n",
    "composite = state_vix + state_vol * 100\n",
    "state_order = composite.sort_values().index\n",
    "state_mapping = {state_order[0]: 0, state_order[1]: 1, state_order[2]: 2}\n",
    "df['regime'] = df['state_raw'].map(state_mapping)\n",
    "\n",
    "# Add state probabilities (after relabeling)\n",
    "for i in range(3):\n",
    "    old_state = [k for k, v in state_mapping.items() if v == i][0]\n",
    "    df[f'regime_{i}_prob'] = state_probs[:, old_state]\n",
    "\n",
    "print(f\"\\nRegime distribution:\")\n",
    "print(df['regime'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identify Regime Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify transitions\n",
    "df['regime_prev'] = df['regime'].shift(1)\n",
    "df['is_transition'] = (df['regime'] != df['regime_prev']).astype(int)\n",
    "\n",
    "# Compute regime persistence (days in current regime)\n",
    "regime_changes = df['is_transition']\n",
    "regime_change_idx = regime_changes.cumsum()\n",
    "df['regime_persistence'] = df.groupby(regime_change_idx).cumcount() + 1\n",
    "\n",
    "# 1-day forward return (in bps)\n",
    "df['spread_ret_1d'] = df['spread'].shift(-1) - df['spread']\n",
    "\n",
    "# Transaction cost: 5 bps round-trip\n",
    "TRANSACTION_COST_BPS = 5.0\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"\\nTotal transitions: {df['is_transition'].sum()}\")\n",
    "print(f\"Transition rate: {df['is_transition'].mean():.2%}\")\n",
    "\n",
    "# Transition matrix\n",
    "transitions_df = df[df['is_transition'] == 1].copy()\n",
    "transition_counts = pd.crosstab(transitions_df['regime_prev'], transitions_df['regime'])\n",
    "print(f\"\\nTransition counts:\")\n",
    "print(transition_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Label Profitable Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_transition_profitability(row, cost_bps=5.0):\n",
    "    \"\"\"\n",
    "    Label transition as profitable (1) or not (0) after costs.\n",
    "    \n",
    "    Strategy: At transition from state A → state B,\n",
    "    trade spread directionally based on expected state characteristics.\n",
    "    \n",
    "    Simple rule: \n",
    "    - If transitioning to higher stress state (0→1, 0→2, 1→2): expect spreads to widen → short spread\n",
    "    - If transitioning to lower stress state (2→1, 2→0, 1→0): expect spreads to tighten → long spread\n",
    "    \n",
    "    P&L = position * spread_ret_1d - cost\n",
    "    \"\"\"\n",
    "    if row['is_transition'] == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    from_state = row['regime_prev']\n",
    "    to_state = row['regime']\n",
    "    spread_ret = row['spread_ret_1d']\n",
    "    \n",
    "    # Determine position based on transition direction\n",
    "    if to_state > from_state:\n",
    "        # Transitioning to higher stress: short spread (position = -1)\n",
    "        # Profit if spread widens (positive spread_ret)\n",
    "        position = -1\n",
    "    elif to_state < from_state:\n",
    "        # Transitioning to lower stress: long spread (position = +1)\n",
    "        # Profit if spread tightens (negative spread_ret)\n",
    "        position = +1\n",
    "    else:\n",
    "        # No transition (shouldn't happen given is_transition==1)\n",
    "        return np.nan\n",
    "    \n",
    "    # P&L in bps (gross)\n",
    "    pnl_gross = position * spread_ret\n",
    "    \n",
    "    # Net P&L after costs\n",
    "    pnl_net = pnl_gross - cost_bps\n",
    "    \n",
    "    # Label: 1 if profitable, 0 if not\n",
    "    return 1 if pnl_net > 0 else 0\n",
    "\n",
    "# Apply labeling\n",
    "df['transition_profitable'] = df.apply(\n",
    "    lambda row: label_transition_profitability(row, TRANSACTION_COST_BPS), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Compute gross and net P&L for analysis\n",
    "def compute_transition_pnl(row, cost_bps=5.0):\n",
    "    if row['is_transition'] == 0:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    from_state = row['regime_prev']\n",
    "    to_state = row['regime']\n",
    "    spread_ret = row['spread_ret_1d']\n",
    "    \n",
    "    if to_state > from_state:\n",
    "        position = -1\n",
    "    elif to_state < from_state:\n",
    "        position = +1\n",
    "    else:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    pnl_gross = position * spread_ret\n",
    "    pnl_net = pnl_gross - cost_bps\n",
    "    \n",
    "    return position, pnl_gross, pnl_net\n",
    "\n",
    "df[['transition_position', 'transition_pnl_gross', 'transition_pnl_net']] = df.apply(\n",
    "    lambda row: pd.Series(compute_transition_pnl(row, TRANSACTION_COST_BPS)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Statistics on transitions only\n",
    "trans_df = df[df['is_transition'] == 1].copy()\n",
    "\n",
    "print(f\"\\nTransition profitability (after {TRANSACTION_COST_BPS} bps costs):\")\n",
    "print(f\"  Total transitions: {len(trans_df)}\")\n",
    "print(f\"  Profitable: {(trans_df['transition_profitable'] == 1).sum()} ({(trans_df['transition_profitable'] == 1).mean():.1%})\")\n",
    "print(f\"  Unprofitable: {(trans_df['transition_profitable'] == 0).sum()} ({(trans_df['transition_profitable'] == 0).mean():.1%})\")\n",
    "print(f\"\\nP&L statistics (bps):\")\n",
    "print(f\"  Mean gross P&L: {trans_df['transition_pnl_gross'].mean():.2f}\")\n",
    "print(f\"  Mean net P&L: {trans_df['transition_pnl_net'].mean():.2f}\")\n",
    "print(f\"  Median net P&L: {trans_df['transition_pnl_net'].median():.2f}\")\n",
    "print(f\"  Std net P&L: {trans_df['transition_pnl_net'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering for Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transition_features(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create features specific to regime transitions.\n",
    "    \n",
    "    Categories:\n",
    "    1. Transition characteristics (from/to states)\n",
    "    2. HMM scores (probabilities, entropy, persistence)\n",
    "    3. Macro/micro context at transition\n",
    "    4. Local shape features (momentum, acceleration)\n",
    "    \"\"\"\n",
    "    df_feat = data.copy()\n",
    "    \n",
    "    # 1. Transition type (one-hot)\n",
    "    df_feat['trans_0to1'] = ((df_feat['regime_prev'] == 0) & (df_feat['regime'] == 1)).astype(int)\n",
    "    df_feat['trans_0to2'] = ((df_feat['regime_prev'] == 0) & (df_feat['regime'] == 2)).astype(int)\n",
    "    df_feat['trans_1to0'] = ((df_feat['regime_prev'] == 1) & (df_feat['regime'] == 0)).astype(int)\n",
    "    df_feat['trans_1to2'] = ((df_feat['regime_prev'] == 1) & (df_feat['regime'] == 2)).astype(int)\n",
    "    df_feat['trans_2to0'] = ((df_feat['regime_prev'] == 2) & (df_feat['regime'] == 0)).astype(int)\n",
    "    df_feat['trans_2to1'] = ((df_feat['regime_prev'] == 2) & (df_feat['regime'] == 1)).astype(int)\n",
    "    \n",
    "    # 2. HMM scores\n",
    "    # Regime confidence: probability of current state\n",
    "    df_feat['regime_confidence'] = df_feat.apply(\n",
    "        lambda row: row[f'regime_{int(row[\"regime\"])}_prob'] if not np.isnan(row['regime']) else np.nan,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Regime entropy: uncertainty in state classification\n",
    "    df_feat['regime_entropy'] = df_feat[['regime_0_prob', 'regime_1_prob', 'regime_2_prob']].apply(\n",
    "        lambda row: entropy(row.values + 1e-10), axis=1\n",
    "    )\n",
    "    \n",
    "    # Persistence in previous regime\n",
    "    df_feat['prev_regime_persistence'] = df_feat['regime_persistence'].shift(1)\n",
    "    \n",
    "    # 3. Macro/micro context\n",
    "    df_feat['vix_level'] = df_feat['vix']\n",
    "    df_feat['vix_chg_5d'] = df_feat['vix'].diff(5)\n",
    "    df_feat['spread_level'] = df_feat['spread']\n",
    "    df_feat['spread_vol_10d'] = df_feat['spread'].rolling(10).std()\n",
    "    df_feat['dgs10_level'] = df_feat['dgs10']\n",
    "    df_feat['dgs10_chg_5d'] = df_feat['dgs10'].diff(5)\n",
    "    \n",
    "    # 4. Local shape features\n",
    "    df_feat['spread_mom_5d'] = df_feat['spread'] - df_feat['spread'].shift(5)\n",
    "    df_feat['spread_mom_10d'] = df_feat['spread'] - df_feat['spread'].shift(10)\n",
    "    df_feat['spread_accel_5d'] = df_feat['spread_mom_5d'] - df_feat['spread_mom_5d'].shift(5)\n",
    "    df_feat['vix_mom_5d'] = df_feat['vix'] - df_feat['vix'].shift(5)\n",
    "    \n",
    "    # LQD microstructure\n",
    "    df_feat['lqd_ret_5d'] = df_feat['lqd_return'].rolling(5).sum()\n",
    "    df_feat['lqd_vol_20d'] = df_feat['lqd_return'].rolling(20).std()\n",
    "    \n",
    "    return df_feat\n",
    "\n",
    "# Create features\n",
    "df_features = create_transition_features(df)\n",
    "df_features = df_features.dropna()\n",
    "\n",
    "print(f\"Features created: {len(df_features)} observations\")\n",
    "\n",
    "# Extract transition-only dataset\n",
    "trans_features = df_features[df_features['is_transition'] == 1].copy()\n",
    "\n",
    "print(f\"Transition-only dataset: {len(trans_features)} transitions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk-forward split\n",
    "TRAIN_END = '2020-12-31'\n",
    "TEST_START = '2021-01-01'\n",
    "\n",
    "train_trans = trans_features.loc[:TRAIN_END]\n",
    "test_trans = trans_features.loc[TEST_START:]\n",
    "\n",
    "print(f\"Train transitions: {len(train_trans)} ({train_trans.index.min().date()} to {train_trans.index.max().date()})\")\n",
    "print(f\"Test transitions: {len(test_trans)} ({test_trans.index.min().date()} to {test_trans.index.max().date()})\")\n",
    "\n",
    "print(f\"\\nTrain profitability: {(train_trans['transition_profitable'] == 1).mean():.1%}\")\n",
    "print(f\"Test profitability: {(test_trans['transition_profitable'] == 1).mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ML Classifier: Filter Profitable Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature set\n",
    "feature_cols = [\n",
    "    # Transition type\n",
    "    'trans_0to1', 'trans_0to2', 'trans_1to0', 'trans_1to2', 'trans_2to0', 'trans_2to1',\n",
    "    # HMM scores\n",
    "    'regime_confidence', 'regime_entropy', 'prev_regime_persistence',\n",
    "    # Macro/micro context\n",
    "    'vix_level', 'vix_chg_5d', 'spread_level', 'spread_vol_10d',\n",
    "    'dgs10_level', 'dgs10_chg_5d',\n",
    "    # Shape\n",
    "    'spread_mom_5d', 'spread_mom_10d', 'spread_accel_5d', 'vix_mom_5d',\n",
    "    # Microstructure\n",
    "    'lqd_ret_5d', 'lqd_vol_20d'\n",
    "]\n",
    "\n",
    "X_train = train_trans[feature_cols]\n",
    "y_train = train_trans['transition_profitable']\n",
    "\n",
    "X_test = test_trans[feature_cols]\n",
    "y_test = test_trans['transition_profitable']\n",
    "\n",
    "print(f\"Feature set: {len(feature_cols)} features\")\n",
    "print(f\"Training set: {len(X_train)} transitions\")\n",
    "print(f\"Test set: {len(X_test)} transitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    min_samples_split=20,\n",
    "    class_weight='balanced',  # Handle class imbalance\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest classifier...\")\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = clf.predict(X_train_scaled)\n",
    "y_test_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "y_train_proba = clf.predict_proba(X_train_scaled)[:, 1]\n",
    "y_test_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Training performance\n",
    "print(f\"\\nTraining accuracy: {accuracy_score(y_train, y_train_pred):.3f}\")\n",
    "print(f\"Training AUC: {roc_auc_score(y_train, y_train_proba):.3f}\")\n",
    "\n",
    "# Test performance\n",
    "print(f\"\\nTest accuracy: {accuracy_score(y_test, y_test_pred):.3f}\")\n",
    "print(f\"Test AUC: {roc_auc_score(y_test, y_test_proba):.3f}\")\n",
    "print(f\"\\nClassification Report (Test):\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Unprofitable', 'Profitable']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. KNN Similarity Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train KNN on historical profitable transitions\n",
    "K_NEIGHBORS = 5\n",
    "\n",
    "# Get profitable transitions from training set\n",
    "profitable_trans_train = train_trans[train_trans['transition_profitable'] == 1]\n",
    "X_profitable_train = scaler.transform(profitable_trans_train[feature_cols])\n",
    "\n",
    "print(f\"Profitable transitions in training set: {len(profitable_trans_train)}\")\n",
    "\n",
    "# Fit KNN\n",
    "knn = NearestNeighbors(n_neighbors=K_NEIGHBORS, metric='euclidean')\n",
    "knn.fit(X_profitable_train)\n",
    "\n",
    "# For each test transition, compute similarity score\n",
    "# Similarity = 1 / (1 + mean_distance_to_k_nearest_profitable_transitions)\n",
    "distances, indices = knn.kneighbors(X_test_scaled)\n",
    "mean_distances = distances.mean(axis=1)\n",
    "similarity_scores = 1.0 / (1.0 + mean_distances)\n",
    "\n",
    "print(f\"\\nSimilarity score statistics:\")\n",
    "print(f\"  Mean: {similarity_scores.mean():.3f}\")\n",
    "print(f\"  Median: {np.median(similarity_scores):.3f}\")\n",
    "print(f\"  Min: {similarity_scores.min():.3f}\")\n",
    "print(f\"  Max: {similarity_scores.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Composite Scoring System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine scores:\n",
    "# 1. ML probability (from Random Forest)\n",
    "# 2. Similarity score (from KNN)\n",
    "# 3. HMM confidence (regime probability)\n",
    "\n",
    "# Weights (can be optimized, but start equal)\n",
    "W_ML = 0.5\n",
    "W_SIMILARITY = 0.3\n",
    "W_HMM = 0.2\n",
    "\n",
    "# Get HMM confidence for test set\n",
    "hmm_confidence_test = test_trans['regime_confidence'].values\n",
    "\n",
    "# Composite score\n",
    "composite_score = (\n",
    "    W_ML * y_test_proba +\n",
    "    W_SIMILARITY * similarity_scores +\n",
    "    W_HMM * hmm_confidence_test\n",
    ")\n",
    "\n",
    "# Add to test dataframe\n",
    "test_trans = test_trans.copy()\n",
    "test_trans['ml_score'] = y_test_proba\n",
    "test_trans['similarity_score'] = similarity_scores\n",
    "test_trans['composite_score'] = composite_score\n",
    "\n",
    "print(f\"Composite score statistics:\")\n",
    "print(test_trans['composite_score'].describe())\n",
    "\n",
    "# Correlation with profitability\n",
    "corr = test_trans[['composite_score', 'transition_profitable']].corr().iloc[0, 1]\n",
    "print(f\"\\nCorrelation with profitability: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Backtest: Trade Only High-Score Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_transition_strategy(transitions_df: pd.DataFrame, score_threshold: float) -> Dict:\n",
    "    \"\"\"\n",
    "    Backtest: trade transitions with composite_score >= threshold.\n",
    "    \n",
    "    Each trade:\n",
    "    - Enter at transition\n",
    "    - Hold exactly 1 day\n",
    "    - P&L = transition_pnl_net (already includes 5 bps cost)\n",
    "    \"\"\"\n",
    "    # Filter by score\n",
    "    traded_trans = transitions_df[transitions_df['composite_score'] >= score_threshold].copy()\n",
    "    \n",
    "    n_trades = len(traded_trans)\n",
    "    if n_trades == 0:\n",
    "        return {\n",
    "            'n_trades': 0,\n",
    "            'hit_ratio': 0,\n",
    "            'mean_pnl': 0,\n",
    "            'total_pnl': 0,\n",
    "            'sharpe': 0\n",
    "        }\n",
    "    \n",
    "    hit_ratio = (traded_trans['transition_profitable'] == 1).mean()\n",
    "    mean_pnl = traded_trans['transition_pnl_net'].mean()\n",
    "    total_pnl = traded_trans['transition_pnl_net'].sum()\n",
    "    std_pnl = traded_trans['transition_pnl_net'].std()\n",
    "    \n",
    "    # Sharpe (annualized): assume 252 trading days, but trades are sparse\n",
    "    # Compute as: mean / std * sqrt(252)\n",
    "    sharpe = (mean_pnl / std_pnl) * np.sqrt(252) if std_pnl > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'threshold': score_threshold,\n",
    "        'n_trades': n_trades,\n",
    "        'hit_ratio': hit_ratio,\n",
    "        'mean_pnl': mean_pnl,\n",
    "        'total_pnl': total_pnl,\n",
    "        'std_pnl': std_pnl,\n",
    "        'sharpe': sharpe\n",
    "    }\n",
    "\n",
    "# Test multiple thresholds\n",
    "thresholds = np.arange(0.3, 0.8, 0.05)\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    res = backtest_transition_strategy(test_trans, threshold)\n",
    "    results.append(res)\n",
    "    print(f\"Threshold {threshold:.2f}: {res['n_trades']:3d} trades, Hit ratio: {res['hit_ratio']:.1%}, \"\n",
    "          f\"Mean P&L: {res['mean_pnl']:6.2f} bps, Sharpe: {res['sharpe']:6.2f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Find best Sharpe\n",
    "best_idx = results_df['sharpe'].idxmax()\n",
    "best_result = results_df.loc[best_idx]\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"BEST RESULT (by Sharpe):\")\n",
    "print(f\"  Threshold: {best_result['threshold']:.2f}\")\n",
    "print(f\"  Trades: {best_result['n_trades']:.0f}\")\n",
    "print(f\"  Hit ratio: {best_result['hit_ratio']:.1%}\")\n",
    "print(f\"  Mean P&L: {best_result['mean_pnl']:.2f} bps\")\n",
    "print(f\"  Total P&L: {best_result['total_pnl']:.2f} bps\")\n",
    "print(f\"  Sharpe: {best_result['sharpe']:.2f}\")\n",
    "print(f\"=\"*80)\n",
    "\n",
    "# Baseline: trade ALL transitions\n",
    "baseline = backtest_transition_strategy(test_trans, threshold=0.0)\n",
    "print(f\"\\nBASELINE (trade all transitions):\")\n",
    "print(f\"  Trades: {baseline['n_trades']}\")\n",
    "print(f\"  Hit ratio: {baseline['hit_ratio']:.1%}\")\n",
    "print(f\"  Mean P&L: {baseline['mean_pnl']:.2f} bps\")\n",
    "print(f\"  Sharpe: {baseline['sharpe']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Sharpe vs threshold\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(results_df['threshold'], results_df['sharpe'], marker='o', linewidth=2, markersize=6, color='darkblue')\n",
    "ax.axhline(0, color='red', linestyle='--', alpha=0.5, label='Sharpe = 0')\n",
    "ax.axhline(baseline['sharpe'], color='orange', linestyle='--', alpha=0.7, label=f'Baseline (all trans): {baseline[\"sharpe\"]:.2f}')\n",
    "ax.set_xlabel('Composite Score Threshold')\n",
    "ax.set_ylabel('Sharpe Ratio')\n",
    "ax.set_title('Sharpe Ratio by Filtering Threshold (Out-of-Sample)', fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(results_df['threshold'], results_df['n_trades'], marker='s', linewidth=2, markersize=6, color='green')\n",
    "ax.set_xlabel('Composite Score Threshold')\n",
    "ax.set_ylabel('Number of Trades')\n",
    "ax.set_title('Trade Count by Filtering Threshold', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/transition_strategy_threshold_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': clf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top_n = 15\n",
    "top_features = feature_importance.head(top_n)\n",
    "ax.barh(range(len(top_features)), top_features['importance'], color='steelblue')\n",
    "ax.set_yticks(range(len(top_features)))\n",
    "ax.set_yticklabels(top_features['feature'])\n",
    "ax.set_xlabel('Feature Importance')\n",
    "ax.set_title(f'Top {top_n} Features for Transition Profitability', fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/transition_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "feature_importance.to_csv('../results/transition_trading/feature_importance.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Final Verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*100)\n",
    "print(\"FINAL VERDICT: TRANSITION TRADING STRATEGY\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(f\"\\n1. BASELINE (trade all transitions):\")\n",
    "print(f\"   Sharpe: {baseline['sharpe']:.2f}\")\n",
    "print(f\"   Hit ratio: {baseline['hit_ratio']:.1%}\")\n",
    "print(f\"   Mean P&L: {baseline['mean_pnl']:.2f} bps\")\n",
    "print(f\"   Total trades: {baseline['n_trades']}\")\n",
    "\n",
    "print(f\"\\n2. BEST FILTERED STRATEGY:\")\n",
    "print(f\"   Threshold: {best_result['threshold']:.2f}\")\n",
    "print(f\"   Sharpe: {best_result['sharpe']:.2f}\")\n",
    "print(f\"   Hit ratio: {best_result['hit_ratio']:.1%}\")\n",
    "print(f\"   Mean P&L: {best_result['mean_pnl']:.2f} bps\")\n",
    "print(f\"   Total trades: {best_result['n_trades']:.0f}\")\n",
    "\n",
    "print(f\"\\n3. IMPROVEMENT:\")\n",
    "sharpe_improvement = best_result['sharpe'] - baseline['sharpe']\n",
    "print(f\"   Sharpe improvement: {sharpe_improvement:+.2f}\")\n",
    "print(f\"   Hit ratio improvement: {(best_result['hit_ratio'] - baseline['hit_ratio']):.1%}\")\n",
    "print(f\"   Trade reduction: {(1 - best_result['n_trades']/baseline['n_trades']):.1%}\")\n",
    "\n",
    "print(f\"\\n4. REALITY CHECK:\")\n",
    "if best_result['sharpe'] > 0.7:\n",
    "    print(f\"   ✓ Strategy PASSES reality check (Sharpe > 0.7)\")\n",
    "    print(f\"   ✓ Filtering improves performance vs baseline\")\n",
    "    print(f\"   ✓ Hit ratio: {best_result['hit_ratio']:.1%} (above 50%)\")\n",
    "elif best_result['sharpe'] > 0 and best_result['sharpe'] > baseline['sharpe']:\n",
    "    print(f\"   ~ Strategy shows modest improvement\")\n",
    "    print(f\"   ~ Sharpe positive but below 0.7 threshold\")\n",
    "    print(f\"   ~ Filtering helps but edge is marginal\")\n",
    "else:\n",
    "    print(f\"   ✗ Strategy FAILS reality check\")\n",
    "    print(f\"   ✗ Sharpe below viability threshold\")\n",
    "    print(f\"   ✗ Filtering does not create exploitable edge\")\n",
    "\n",
    "print(f\"\\n5. KEY INSIGHTS:\")\n",
    "print(f\"   - Regime transitions are {(test_trans['is_transition']==1).sum()} events in test period\")\n",
    "print(f\"   - Baseline profitability: {baseline['hit_ratio']:.1%}\")\n",
    "print(f\"   - ML+KNN filtering improves selectivity\")\n",
    "print(f\"   - 1-day holding period (no optimization)\")\n",
    "print(f\"   - Transaction costs: {TRANSACTION_COST_BPS} bps included\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('../results/transition_trading/threshold_analysis.csv', index=False)\n",
    "test_trans.to_csv('../results/transition_trading/test_transitions_scored.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook tested whether machine learning can filter regime transitions to identify profitable 1-day directional trades.\n",
    "\n",
    "**Approach:**\n",
    "1. Identified all HMM regime transitions\n",
    "2. Labeled transitions as profitable/unprofitable after 5 bps costs\n",
    "3. Trained Random Forest + KNN to filter high-quality transitions\n",
    "4. Combined ML probability + similarity score + HMM confidence\n",
    "5. Backtested: trade only transitions with high composite score\n",
    "\n",
    "**Key question:** Does filtering improve Sharpe vs trading all transitions?\n",
    "\n",
    "**Fixed parameters:**\n",
    "- Horizon: 1 day (no optimization)\n",
    "- Costs: 5 bps round-trip\n",
    "- Direction: Based on transition type (stress up/down)\n",
    "\n",
    "**Files generated:**\n",
    "- `results/transition_trading/threshold_analysis.csv`\n",
    "- `results/transition_trading/test_transitions_scored.csv`\n",
    "- `results/transition_trading/feature_importance.csv`\n",
    "- `results/figures/transition_strategy_threshold_analysis.png`\n",
    "- `results/figures/transition_feature_importance.png`\n",
    "\n",
    "---\n",
    "\n",
    "**Next steps IF strategy shows promise (Sharpe > 0.7):**\n",
    "1. Regime-conditional analysis (which transitions work best?)\n",
    "2. SHAP analysis for interpretability\n",
    "3. Robustness tests (varying costs, alternative features)\n",
    "4. Real-time implementation considerations\n",
    "\n",
    "**If strategy fails:** Accept that even filtered transitions are not exploitable given transaction costs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
